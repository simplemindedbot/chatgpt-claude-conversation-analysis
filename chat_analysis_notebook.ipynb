{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Analysis Dashboard\n",
    "\n",
    "This notebook provides comprehensive analysis and visualization of your processed AI chat conversations.\n",
    "\n",
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting styles\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ðŸ“Š Analysis libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the processed database\n",
    "conn = sqlite3.connect('chat_analysis.db')\n",
    "\n",
    "# Load all data tables\n",
    "print(\"Loading processed chat data...\")\n",
    "\n",
    "# Raw conversations\n",
    "conversations_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT * FROM raw_conversations\n",
    "\"\"\", conn)\n",
    "\n",
    "# Message features\n",
    "features_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT * FROM message_features\n",
    "\"\"\", conn)\n",
    "\n",
    "# Conversation-level features\n",
    "conv_features_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT * FROM conversation_features\n",
    "\"\"\", conn)\n",
    "\n",
    "# Combined view\n",
    "combined_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        r.*,\n",
    "        mf.content_type,\n",
    "        mf.sentiment_score,\n",
    "        mf.has_code,\n",
    "        mf.has_urls,\n",
    "        mf.has_questions\n",
    "    FROM raw_conversations r\n",
    "    JOIN message_features mf ON r.message_id = mf.message_id\n",
    "\"\"\", conn)\n",
    "\n",
    "# Convert timestamps\n",
    "combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'])\n",
    "conversations_df['timestamp'] = pd.to_datetime(conversations_df['timestamp'])\n",
    "\n",
    "print(f\"âœ… Loaded {len(conversations_df):,} messages from {len(conv_features_df):,} conversations\")\n",
    "print(f\"ðŸ“ˆ Data spans from {combined_df['timestamp'].min()} to {combined_df['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Overview Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=== CHAT ANALYSIS OVERVIEW ===\")\n",
    "print(f\"ðŸ“ Total Messages: {len(combined_df):,}\")\n",
    "print(f\"ðŸ’¬ Total Conversations: {combined_df['conversation_id'].nunique():,}\")\n",
    "print(f\"ðŸ¤– AI Sources: {', '.join(combined_df['source_ai'].unique())}\")\n",
    "print(f\"ðŸ“… Date Range: {combined_df['timestamp'].min().strftime('%Y-%m-%d')} to {combined_df['timestamp'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"ðŸ“Š Total Words: {combined_df['word_count'].sum():,}\")\n",
    "print(f\"ðŸ“ˆ Average Words per Message: {combined_df['word_count'].mean():.1f}\")\n",
    "\n",
    "print(\"\\n=== MESSAGE BREAKDOWN ===\")\n",
    "role_counts = combined_df['role'].value_counts()\n",
    "for role, count in role_counts.items():\n",
    "    print(f\"{role}: {count:,} messages ({count/len(combined_df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== CONTENT TYPES ===\")\n",
    "content_counts = combined_df['content_type'].value_counts()\n",
    "for content_type, count in content_counts.items():\n",
    "    print(f\"{content_type.title()}: {count:,} messages ({count/len(combined_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Activity Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messages over time\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['Messages Over Time', 'Messages by AI Source', 'Content Types Distribution', 'Sentiment Distribution'],\n",
    "    specs=[[{\"secondary_y\": True}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"pie\"}, {\"type\": \"histogram\"}]]\n",
    ")\n",
    "\n",
    "# Messages over time by AI source\n",
    "daily_messages = combined_df.groupby([combined_df['timestamp'].dt.date, 'source_ai']).size().reset_index(name='count')\n",
    "for ai_source in combined_df['source_ai'].unique():\n",
    "    ai_data = daily_messages[daily_messages['source_ai'] == ai_source]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=ai_data['timestamp'], y=ai_data['count'], name=ai_source, mode='lines+markers'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Messages by AI source\n",
    "ai_counts = combined_df['source_ai'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Bar(x=ai_counts.index, y=ai_counts.values, name='AI Sources'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Content types pie chart\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=content_counts.index, values=content_counts.values, name=\"Content Types\"),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Sentiment distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=combined_df['sentiment_score'], name='Sentiment', nbinsx=30),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Chat Analysis Dashboard\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ•’ Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time-based features\n",
    "combined_df['hour'] = combined_df['timestamp'].dt.hour\n",
    "combined_df['day_of_week'] = combined_df['timestamp'].dt.day_name()\n",
    "combined_df['month'] = combined_df['timestamp'].dt.month_name()\n",
    "\n",
    "# Hourly activity pattern\n",
    "hourly_activity = combined_df.groupby(['hour', 'source_ai']).size().reset_index(name='count')\n",
    "\n",
    "fig = px.line(hourly_activity, x='hour', y='count', color='source_ai',\n",
    "              title='Chat Activity by Hour of Day',\n",
    "              labels={'hour': 'Hour of Day', 'count': 'Number of Messages'})\n",
    "fig.show()\n",
    "\n",
    "# Day of week activity\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_activity = combined_df.groupby(['day_of_week', 'source_ai']).size().reset_index(name='count')\n",
    "daily_activity['day_of_week'] = pd.Categorical(daily_activity['day_of_week'], categories=day_order, ordered=True)\n",
    "daily_activity = daily_activity.sort_values('day_of_week')\n",
    "\n",
    "fig = px.bar(daily_activity, x='day_of_week', y='count', color='source_ai',\n",
    "             title='Chat Activity by Day of Week',\n",
    "             labels={'day_of_week': 'Day of Week', 'count': 'Number of Messages'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Conversation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation lengths and characteristics\n",
    "print(\"=== CONVERSATION CHARACTERISTICS ===\")\n",
    "print(f\"Average messages per conversation: {conv_features_df['message_count'].mean():.1f}\")\n",
    "print(f\"Median messages per conversation: {conv_features_df['message_count'].median():.1f}\")\n",
    "print(f\"Average words per conversation: {conv_features_df['total_word_count'].mean():.0f}\")\n",
    "print(f\"Average conversation duration: {conv_features_df['duration_minutes'].mean():.1f} minutes\")\n",
    "\n",
    "# Conversation types\n",
    "print(\"\\n=== CONVERSATION TYPES ===\")\n",
    "conv_type_counts = conv_features_df['conversation_type'].value_counts()\n",
    "for conv_type, count in conv_type_counts.items():\n",
    "    print(f\"{conv_type.replace('_', ' ').title()}: {count:,} conversations ({count/len(conv_features_df)*100:.1f}%)\")\n",
    "\n",
    "# Visualize conversation characteristics\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['Conversation Length Distribution', 'Duration vs Messages', 'Conversation Types', 'Complexity vs Idea Density']\n",
    ")\n",
    "\n",
    "# Conversation length distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=conv_features_df['message_count'], name='Message Count', nbinsx=20),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Duration vs Messages scatter\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=conv_features_df['message_count'], y=conv_features_df['duration_minutes'], \n",
    "               mode='markers', name='Duration vs Messages'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Conversation types\n",
    "fig.add_trace(\n",
    "    go.Bar(x=conv_type_counts.index, y=conv_type_counts.values, name='Conversation Types'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Complexity vs Idea Density\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=conv_features_df['complexity_score'], y=conv_features_df['idea_density'],\n",
    "               mode='markers', name='Complexity vs Density'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Conversation Analysis\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Content Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content analysis by AI source\n",
    "content_by_ai = combined_df.groupby(['source_ai', 'content_type']).size().reset_index(name='count')\n",
    "content_pivot = content_by_ai.pivot(index='source_ai', columns='content_type', values='count').fillna(0)\n",
    "\n",
    "# Normalize by percentage\n",
    "content_pivot_pct = content_pivot.div(content_pivot.sum(axis=1), axis=0) * 100\n",
    "\n",
    "fig = px.bar(content_by_ai, x='source_ai', y='count', color='content_type',\n",
    "             title='Content Types by AI Source',\n",
    "             labels={'source_ai': 'AI Source', 'count': 'Number of Messages'})\n",
    "fig.show()\n",
    "\n",
    "# Code vs non-code analysis\n",
    "code_analysis = combined_df.groupby('source_ai').agg({\n",
    "    'has_code': 'sum',\n",
    "    'has_urls': 'sum', \n",
    "    'has_questions': 'sum',\n",
    "    'message_id': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "code_analysis['code_percentage'] = (code_analysis['has_code'] / code_analysis['message_id']) * 100\n",
    "code_analysis['url_percentage'] = (code_analysis['has_urls'] / code_analysis['message_id']) * 100\n",
    "code_analysis['question_percentage'] = (code_analysis['has_questions'] / code_analysis['message_id']) * 100\n",
    "\n",
    "print(\"=== CONTENT CHARACTERISTICS BY AI SOURCE ===\")\n",
    "for _, row in code_analysis.iterrows():\n",
    "    print(f\"\\n{row['source_ai']}:\")\n",
    "    print(f\"  Code messages: {row['code_percentage']:.1f}%\")\n",
    "    print(f\"  URL messages: {row['url_percentage']:.1f}%\")\n",
    "    print(f\"  Question messages: {row['question_percentage']:.1f}%\")\n",
    "\n",
    "# Visualize content characteristics\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(name='Code', x=code_analysis['source_ai'], y=code_analysis['code_percentage']))\n",
    "fig.add_trace(go.Bar(name='URLs', x=code_analysis['source_ai'], y=code_analysis['url_percentage']))\n",
    "fig.add_trace(go.Bar(name='Questions', x=code_analysis['source_ai'], y=code_analysis['question_percentage']))\n",
    "fig.update_layout(title='Content Characteristics by AI Source (%)', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ˜Š Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis by AI and content type\n",
    "sentiment_stats = combined_df.groupby(['source_ai', 'role']).agg({\n",
    "    'sentiment_score': ['mean', 'std', 'count']\n",
    "}).round(3)\n",
    "\n",
    "print(\"=== SENTIMENT ANALYSIS ===\")\n",
    "print(sentiment_stats)\n",
    "\n",
    "# Sentiment over time\n",
    "combined_df['date'] = combined_df['timestamp'].dt.date\n",
    "daily_sentiment = combined_df.groupby(['date', 'source_ai'])['sentiment_score'].mean().reset_index()\n",
    "\n",
    "fig = px.line(daily_sentiment, x='date', y='sentiment_score', color='source_ai',\n",
    "              title='Average Sentiment Over Time',\n",
    "              labels={'date': 'Date', 'sentiment_score': 'Average Sentiment Score'})\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Neutral\")\n",
    "fig.show()\n",
    "\n",
    "# Sentiment distribution by AI source\n",
    "fig = px.box(combined_df, x='source_ai', y='sentiment_score', color='source_ai',\n",
    "             title='Sentiment Score Distribution by AI Source')\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "fig.show()\n",
    "\n",
    "# Sentiment by content type\n",
    "fig = px.box(combined_df, x='content_type', y='sentiment_score', \n",
    "             title='Sentiment by Content Type')\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ† Top Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most productive days\n",
    "daily_counts = combined_df.groupby(combined_df['timestamp'].dt.date).size()\n",
    "top_days = daily_counts.nlargest(10)\n",
    "\n",
    "print(\"=== TOP 10 MOST ACTIVE DAYS ===\")\n",
    "for date, count in top_days.items():\n",
    "    print(f\"{date}: {count} messages\")\n",
    "\n",
    "# Longest conversations\n",
    "longest_convs = conv_features_df.nlargest(10, 'message_count')[['title', 'source_ai', 'message_count', 'total_word_count', 'conversation_type']]\n",
    "print(\"\\n=== TOP 10 LONGEST CONVERSATIONS ===\")\n",
    "for _, conv in longest_convs.iterrows():\n",
    "    title = conv['title'][:50] + \"...\" if len(str(conv['title'])) > 50 else conv['title']\n",
    "    print(f\"{title} ({conv['source_ai']})\")\n",
    "    print(f\"  {conv['message_count']} messages, {conv['total_word_count']:,} words, type: {conv['conversation_type']}\")\n",
    "\n",
    "# Most complex conversations (high code + question content)\n",
    "complex_convs = conv_features_df.nlargest(10, 'complexity_score')[['title', 'source_ai', 'complexity_score', 'conversation_type']]\n",
    "print(\"\\n=== TOP 10 MOST COMPLEX CONVERSATIONS ===\")\n",
    "for _, conv in complex_convs.iterrows():\n",
    "    title = conv['title'][:50] + \"...\" if len(str(conv['title'])) > 50 else conv['title']\n",
    "    print(f\"{title} ({conv['source_ai']})\")\n",
    "    print(f\"  Complexity: {conv['complexity_score']:.2f}, Type: {conv['conversation_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Custom Analysis\n",
    "\n",
    "Use this section to run your own custom queries and analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find all conversations about a specific topic\n",
    "search_term = \"python\"  # Change this to search for specific topics\n",
    "\n",
    "topic_conversations = combined_df[combined_df['content'].str.contains(search_term, case=False, na=False)]\n",
    "topic_conv_ids = topic_conversations['conversation_id'].unique()\n",
    "\n",
    "print(f\"Found {len(topic_conv_ids)} conversations mentioning '{search_term}'\")\n",
    "print(f\"Total messages in these conversations: {len(topic_conversations)}\")\n",
    "\n",
    "# Show some examples\n",
    "if len(topic_conv_ids) > 0:\n",
    "    sample_convs = conv_features_df[conv_features_df['conversation_id'].isin(topic_conv_ids)].head(5)\n",
    "    print(f\"\\nSample conversations:\")\n",
    "    for _, conv in sample_convs.iterrows():\n",
    "        title = conv['title'][:60] + \"...\" if len(str(conv['title'])) > 60 else conv['title']\n",
    "        print(f\"â€¢ {title} ({conv['source_ai']}) - {conv['message_count']} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary data for external use\n",
    "summary_data = {\n",
    "    'total_messages': len(combined_df),\n",
    "    'total_conversations': len(conv_features_df),\n",
    "    'ai_sources': list(combined_df['source_ai'].unique()),\n",
    "    'date_range': {\n",
    "        'start': combined_df['timestamp'].min().isoformat(),\n",
    "        'end': combined_df['timestamp'].max().isoformat()\n",
    "    },\n",
    "    'content_types': content_counts.to_dict(),\n",
    "    'avg_sentiment': combined_df['sentiment_score'].mean(),\n",
    "    'code_percentage': (combined_df['has_code'].sum() / len(combined_df)) * 100\n",
    "}\n",
    "\n",
    "print(\"=== EXPORTABLE SUMMARY ===\")\n",
    "print(json.dumps(summary_data, indent=2, default=str))\n",
    "\n",
    "# Optionally save to file\n",
    "# with open('chat_analysis_summary.json', 'w') as f:\n",
    "#     json.dump(summary_data, f, indent=2, default=str)\n",
    "# print(\"Summary saved to chat_analysis_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Database Connection Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"âœ… Database connection closed\")\n",
    "print(\"ðŸŽ‰ Analysis complete! Feel free to modify and extend this notebook for your specific needs.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}